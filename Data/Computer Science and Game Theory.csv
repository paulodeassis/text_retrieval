Computing the Shapley Value in Allocation Problems: Approximations and Bounds, with an Application to the Italian VQR Research Assessment Program;Francesco Lupia, Angelo Mendicelli, Andrea Ribichini, Francesco Scarcello, Marco Schaerf;In allocation problems, a given set of goods are assigned to agents in such a way that the social welfare is maximised, that is, the largest possible global worth is achieved. When goods are indivisible, it is possible to use money compensation to perform a fair allocation taking into account the actual contribution of all agents to the social welfare. Coalitional games provide a formal mathematical framework to model such problems, in particular the Shapley value is a solution concept widely used for assigning worths to agents in a fair way. Unfortunately, computing this value is a;https://arxiv.org/abs/1709.04176
Data offloading in mobile edge computing: A coalitional game based pricing approach;Tian Zhang, Wei Chen, Feng Yang;Mobile edge computing (MEC), affords service to the vicinity of mobile devices (MDs), has become a key technology for future network. Offloading big data to the MEC server for preprocessing is a attractive choice of MDs. In the paper, we investigate data offloading from MDs to MEC servers. A coalitional game based pricing scheme is proposed. We apply coalitional game to depict the offloading relationship between MDs and MEC servers, and utilize pricing as the stimuli for the offloading. A scheduled MD chooses one MEC server within the same coalition for offloading, and pays the selected MEC server for the MEC service. We formulate a coalitional game, where MDs and MEC servers are players and their utilities are respectively defined. Next, we analyze the formulated game. Specially, the core is studied. Finally, utility performance of the proposed scheme under the 2-MD and 2-MEC- server scenario are demonstrated.;https://arxiv.org/abs/1709.04148
Learning with Opponent-Learning Awareness;Jakob N. Foerster, Richard Y. Chen, Maruan Al-Shedivat, Shimon Whiteson, Pieter Abbeel, Igor Mordatch;Multi-agent settings are quickly gathering importance in machine learning. Beyond a plethora of recent work on deep multi-agent reinforcement learning, hierarchical reinforcement learning, generative adversarial networks and decentralized optimization can all be seen as instances of this setting. However, the presence of multiple learning agents in these settings renders the training problem non-stationary and often leads to unstable training or undesired final results. We present Learning with Opponent-Learning Awareness (LOLA), a method that reasons about the anticipated learning of the other agents. The LOLA learning rule includes an additional term that accounts for the impact of the agent's policy on the anticipated parameter update of the other agents. We show that the LOLA update rule can be efficiently calculated using an extension of the likelihood ratio policy gradient update, making the method suitable for model-free reinforcement learning. This method thus scales to large parameter and input spaces and nonlinear function approximators. Preliminary results show that the encounter of two LOLA agents leads to the emergence of tit-for-tat and therefore cooperation in the infinitely iterated prisoners' dilemma, while independent learning does not. In this domain, LOLA also receives higher payouts compared to a naive learner, and is robust against exploitation by higher order gradient-based methods. Applied to infinitely repeated matching pennies, only LOLA agents converge to the Nash equilibrium. We also apply LOLA to a grid world task with an embedded social dilemma using deep recurrent policies. Again, by considering the learning of the other agent, LOLA agents learn to cooperate out of selfish interests.;https://arxiv.org/abs/1709.04326
Models and Framework for Adversarial Attacks on Complex Adaptive Systems;Vahid Behzadan, Arslan Munir;We introduce the paradigm of adversarial attacks that target the dynamics of Complex Adaptive Systems (CAS). To facilitate the analysis of such attacks, we present multiple approaches to the modeling of CAS as dynamical, data-driven, and game-theoretic systems, and develop quantitative definitions of attack, vulnerability, and resilience in the context of CAS security. Furthermore, we propose a comprehensive set of schemes for classification of attacks and attack surfaces in CAS, complemented with examples of practical attacks. Building on this foundation, we propose a framework based on reinforcement learning for simulation and analysis of attacks on CAS, and demonstrate its performance through three real-world case studies of targeting power grids, destabilization of terrorist organizations, and manipulation of machine learning agents. We also discuss potential mitigation techniques, and remark on future research directions in analysis and design of secure complex adaptive systems.;https://arxiv.org/abs/1709.04137
Enemy At the Gateways: A Game Theoretic Approach to Proxy Distribution;Milad Nasr, Sadegh Farhang, Amir Houmansadr, Jens Grossklags;A core technique used by popular proxy-based circumvention systems like Tor, Psiphon, and Lantern is to secretly share the IP addresses of circumvention proxies with the censored clients for them to be able to use such systems. For instance, such secretly shared proxies are known as bridges in Tor. However, a key challenge to this mechanism is the insider attack problem: censoring agents can impersonate as benign censored clients in order to obtain (and then block) such secretly shared circumvention proxies.;https://arxiv.org/abs/1709.04030
Certified Computation in Crowdsourcing;Themis Gouleakis, Christos Tzamos, Manolis Zampetakis;A wide range of learning tasks require human input in labeling massive data. For this labeling and because of the quantity of the data, crowdsourcing has become very crucial. The collected data though are usually low quality as workers are not appropriately incentivized to put effort. Significant research has focused on designing appropriate incentive schemes but do not capture the full range of tasks that appear in practice. Moreover, even if incentives are theoretically aligned noise in the data can still exist because it is hard to model exactly how workers will behave.;https://arxiv.org/abs/1709.03926
Finite-state Strategies in Delay Games;Martin Zimmermann (Saarland University);What is a finite-state strategy in a delay game? We answer this surprisingly non-trivial question and present a very general framework for computing such strategies: they exist for all winning conditions that are recognized by automata with acceptance conditions that satisfy a certain aggregation property. Our framework also yields upper bounds on the complexity of determining the winner of such delay games and upper bounds on the necessary lookahead to win the game. In particular, we cover all previous results of that kind as special cases of our uniform approach.;https://arxiv.org/abs/1709.03539
On Revenue Monotonicity in Combinatorial Auctions;Andrew Chi-Chih Yao;Along with substantial progress made recently in designing near-optimal mechanisms for multi-item auctions, interesting structural questions have also been raised and studied. In particular, is it true that the seller can always extract more revenue from a market where the buyers value the items higher than another market? In this paper we obtain such a revenue monotonicity result in a general setting. Precisely, consider the revenue-maximizing combinatorial auction for m items and n buyers in the Bayesian setting, specified by a valuation function v and a set F of nm independent item-type distributions. Let REV(v,F) denote the maximum revenue achievable under F by any incentive compatible mechanism. Intuitively, one would expect that REV(v,G)?REV(v,F) if distribution G stochastically dominates F. Surprisingly, Hart and Reny (2012) showed that this is not always true even for the simple case when v is additive. A natural question arises: Are these deviations contained within bounds? To what extent may the monotonicity intuition still be valid? We present an {approximate monotonicity} theorem for the class of fractionally subadditive (XOS) valuation functions v, showing that REV(v,G)?cREV(v,F) if G stochastically dominates F under v where c>0 is a universal constant. Previously, approximate monotonicity was known only for the case n=1: Babaioff et al. (2014) for the class of additive valuations, and Rubinstein and Weinberg (2015) for all subaddtive valuation functions.;https://arxiv.org/abs/1709.03223
When to arrive at a queue with earliness, tardiness and waiting costs;Eliran Sherzer, Yoav Kerner;We consider a queueing facility where customers decide when to arrive. All customers have the same desired arrival time (w.l.o.g.\ time zero). There is one server, and the service times are independent and exponentially distributed. The total number of customers that demand service is random, and follows the Poisson distribution. Each customer wishes to minimize the sum of three costs: earliness, tardiness and waiting. We assume that all three costs are linear with time and are defined as follows. Earliness is the time between arrival and time zero, if there is any. Tardiness is simply the time of entering service, if it is after time zero. Waiting time is the time from arrival until entering service. We focus on customers' rational behaviour, assuming that each customer wants to minimize his total cost, and in particular, we seek a symmetric Nash equilibrium strategy. We show that such a strategy is mixed, unless trivialities occur. We construct a set of equations that its solution provides the symmetric Nash equilibrium. The solution is a continuous distribution on the real line. We also compare the socially optimal solution (that is, the one that minimizes total cost across all customers) to the overall cost resulting from the Nash equilibrium.;https://arxiv.org/abs/1709.03374
Prosocial learning agents solve generalized Stag Hunts better than selfish ones;Alexander Peysakhovich, Adam Lerer;There is much interest in applying reinforcement learning methods to multi-agent systems. A popular way to do so is the method of reactive training -- ie. treating other agents as if they are a stationary part of the learner's environment. Dyads of such learners, if they converge, will converge to Nash equilibria of the game. However, there is an important game theoretic issue here: positive-sum games can have multiple equilibria which differ in their payoffs. We show that even in simple coordination games reactive reinforcement learning agents will often coordinate on equilibria with suboptimal payoffs for both agents. We also show that receiving utility from rewards other agents receive - ie. having prosocial preferences - leads agents to converging to better equilibria in a class of generalized Stag Hunt games. We show this analytically for matrix games and experimentally for more complex Markov versions. Importantly, this is true even if only one of the agents has social preferences. This implies that even if an agent designer only controls a single agent out of a dyad and only cares about their agent's payoff, it can still be better for the designer to make the agent prosocial rather than selfish.;https://arxiv.org/abs/1709.02865
Mixed Integer Programming with Convex/Concave Constraints: Fixed-Parameter Tractability and Applications to Multicovering and Voting;Robert Bredereck, Piotr Faliszewski, Rolf Niedermeier, Piotr Skowron, Nimrod Talmon;A classic result of Lenstra [Math.~Oper.~Res.~1983] says that an integer linear program can be solved in fixed-parameter tractable (FPT) time for the parameter being the number of variables. We extend this result by incorporating non-decreasing piecewise linear convex or concave functions to our (mixed) integer programs. This general technique allows us to establish parameterized complexity of a number of classic computational problems. In particular, we prove that Weighted Set Multicover is in FPT when parameterized by the number of elements to cover, and that there exists an FPT-time approximation scheme for Multiset Multicover for the same parameter. Further, we use our general technique to prove that a number of problems from computational social choice (e.g., problems related to bribery and control in elections) are in FPT when parameterized by the number of candidates. For bribery, this resolves a nearly 10-year old family of open problems, and for weighted electoral control of Approval voting, this improves some previously known XP-memberships to FPT-memberships.;https://arxiv.org/abs/1709.02850
Cycles in adversarial regularized learning;Panayotis Mertikopoulos, Christos Papadimitriou, Georgios Piliouras;Regularized learning is a fundamental technique in online optimization, machine learning and many other fields of computer science. A natural question that arises in these settings is how regularized learning algorithms behave when faced against each other. We study a natural formulation of this problem by coupling regularized learning dynamics in zero-sum games. We show that the system's behavior is Poincar\'e recurrent, implying that almost every trajectory revisits any (arbitrarily small) neighborhood of its starting point infinitely often. This cycling behavior is robust to the agents' choice of regularization mechanism (each agent could be using a different regularizer), to positive-affine transformations of the agents' utilities, and it also persists in the case of networked competition, i.e., for zero-sum polymatrix games.;https://arxiv.org/abs/1709.02738
On Democratic Fairness for Groups of Agents;Erel Segal-Halevi, Warut Suksompong;We study the problem of allocating indivisible goods to groups of interested agents in a fair manner. The agents in the same group share the same set of goods even though they may have different preferences from one another. Previous work on this model has shown positive results that hold either asymptotically or for groups with a small number of agents. Using the concept of democratic fairness, which aims to satisfy a certain fraction of the agents in each group, we provide fairness guarantees that hold for general instances. In particular, we show that for two groups with any number of agents, there exists an allocation that is envy-free up to one good and yields at least half of the maximin share for at least half of the agents in each group.;https://arxiv.org/abs/1709.02564
Game Theory Models for the Verification of the Collective Behaviour of Autonomous Cars;László Z. Varga (ELTE Eötvös Loránd University);The collective of autonomous cars is expected to generate almost optimal traffic. In this position paper we discuss the multi-agent models and the verification results of the collective behaviour of autonomous cars. We argue that non-cooperative autonomous adaptation cannot guarantee optimal behaviour. The conjecture is that intention aware adaptation with a constraint on simultaneous decision making has the potential to avoid unwanted behaviour. The online routing game model is expected to be the basis to formally prove this conjecture.;https://arxiv.org/abs/1709.02556
Dynamics and Coalitions in Sequential Games;Thomas Brihaye (UMONS), Gilles Geeraerts (Université libre de Bruxelles), Marion Hallet (UMONS), Stéphane Le Roux (Université libre de Bruxelles);We consider N-player non-zero sum games played on finite trees (i.e., sequential games), in which the players have the right to repeatedly update their respective strategies (for instance, to improve the outcome wrt to the current strategy profile). This generates a dynamics in the game which may eventually stabilise to a Nash Equilibrium (as with Kukushkin's lazy improvement), and we argue that it is interesting to study the conditions that guarantee such a dynamics to terminate. ;https://arxiv.org/abs/1709.02100
An Existence Theorem of Nash Equilibrium in Coq and Isabelle;Stéphane Le Roux (Université Libre de Bruxelles), Érik Martin-Dorel (IRIT, Université de Toulouse), Jan-Georg Smaus (IRIT, Université de Toulouse);Nash equilibrium (NE) is a central concept in game theory. Here we prove formally a published theorem on existence of an NE in two proof assistants, Coq and Isabelle: starting from a game with finitely many outcomes, one may derive a game by rewriting each of these outcomes with either of two basic outcomes, namely that Player 1 wins or that Player 2 wins. If all ways of deriving such a win/lose game lead to a game where one player has a winning strategy, the original game also has a Nash equilibrium.;https://arxiv.org/abs/1709.02096
Robust Exponential Worst Cases for Divide-et-Impera Algorithms for Parity Games;Massimo Benerecetti (Università degli Studi di Napoli Federico II), Daniele Dell'Erba (Università degli Studi di Napoli Federico II), Fabio Mogavero (Università degli Studi di Verona);The McNaughton-Zielonka divide et impera algorithm is the simplest and most flexible approach available in the literature for determining the winner in a parity game. Despite its theoretical worst-case complexity and the negative reputation as a poorly effective algorithm in practice, it has been shown to rank among the best techniques for the solution of such games. Also, it proved to be resistant to a lower bound attack, even more than the strategy improvements approaches, and only recently a family of games on which the algorithm requires exponential time has been provided by Friedmann. An easy analysis of this family shows that a simple memoization technique can help the algorithm solve the family in polynomial time. The same result can also be achieved by exploiting an approach based on the dominion-decomposition techniques proposed in the literature. These observations raise the question whether a suitable combination of dynamic programming and game-decomposition techniques can improve on the exponential worst case of the original algorithm. In this paper we answer this question negatively, by providing a robustly exponential worst case, showing that no intertwining of the above mentioned techniques can help mitigating the exponential nature of the divide et impera approaches.;https://arxiv.org/abs/1709.02099
Probabilistic Analysis Based On Symbolic Game Semantics and Model Counting;Aleksandar S. Dimovski (IT University of Copenhagen);Probabilistic program analysis aims to quantify the probability that a given program satisfies a required property. It has many potential applications, from program understanding and debugging to computing program reliability, compiler optimizations and quantitative information flow analysis for security. In these situations, it is usually more relevant to quantify the probability of satisfying/violating a given property than to just assess the possibility of such events to occur.;https://arxiv.org/abs/1709.02092
Stabilizing Weighted Graphs;Zhuan Khye Koh, Laura Sanità;"An edge-weighted graph G=(V,E) is called stable if the value of a maximum-weight matching equals the value of a maximum-weight fractional matching. Stable graphs play an important role in some interesting game theory problems, such as network bargaining games and cooperative matching games, because they characterize instances which admit stable outcomes. Motivated by this, in the last few years many researchers have investigated the algorithmic problem of turning a given graph into a stable one, via edge- and vertex-removal operations. However, all the algorithmic results developed in the literature so far only hold for unweighted instances, i.e., assuming unit weights on the edges of G. 
We give the first polynomial-time algorithm to find a minimum cardinality subset of vertices whose removal from G yields a stable graph, for any weighted graph G. The algorithm is combinatorial and exploits new structural properties of basic fractional matchings, which may be of independent interest. In contrast, we show that the problem of finding a minimum cardinality subset of edges whose removal from a weighted graph G yields a stable graph, does not admit any constant-factor approximation algorithm, unless P=NP. In this setting, we develop an O(?)-approximation algorithm for the problem, where ? is the maximum degree of a node in G.";https://arxiv.org/abs/1709.01982
